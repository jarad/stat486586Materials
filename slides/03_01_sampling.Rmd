---
title: "Sampling"
subtitle: "STAT486/586"
author: "Xiongtao Dai"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: [myslides.css, myslides-fonts.css]
    lib_dir: libs
    nature:
      beforeInit: "macros.js"
      highlightLines: true
      countIncrementalSlides: false
---
class: big, middle

```{r xaringan-tile-view, echo=FALSE}
xaringanExtra::use_tile_view()
```

## Module 3: Simulation and Resampling Methods


---

## Outline

- Probability in R

- Pseudo random number generation

- Case study

- Random sampling

---

## Density function

The *density function* $f(x)$ for a continuous random variable $X$ describes how likely it is for $X$ to lie close to $x$ on the support

- often abbreviated as *pdf* (probability density function)
- for a discrete r.v., the analogy is *pmf* (probability mass function)

```{r, echo=FALSE, fig.height=4, fig.width=4, fig.align='center'}
x <- seq(-5, 5, by=0.05)
plot(x, dnorm(x), type='l', ylab='f(x)', main="Standard normal density")
```

- `dnorm(x, mean, sd)` returns the density values for any normal distribution

---

## Distribution function

The *distribution function* for a continuous r.v. $X$ is the probability for $X$ to be at most $x$, namely 
$$F(x) = P(X \le x) = \int_{-\infty}^x f(x) dx.$$

- often abbreviated as *cdf* (cumulative distribution function)
- For a discrete r.v., the integral becomes a summation over pmf values. In this case $F(x)$ can be discontinuous
<!-- - $F(x)$ is the probability for $X$ to be at most $x$ -->
```{r, echo=FALSE, fig.height=3.5, fig.width=3.5, fig.align='center'}
plot(x, pnorm(x), type='l', ylab='F(x)', main="Standard normal cdf")
```
- `pnorm(x, mean, sd)` returns the normal cdf values


---

## Quantile function

The *quantile function* for a continuous r.v. $X$ is the inverse of the cdf
$$Q(p) = F^{-1}(p).$$
For any probability $p \in [0,1]$, a $p$-quantile of the distribution is a value such that there is $p$ amount of mass lying below the quantile.
```{r, echo=FALSE, results='hide', fig.height=3.8, fig.width=8, fig.align='center'}
par(mfrow=c(1, 2))
p <- seq(0, 1, length.out=1000)
plot(p, qnorm(p), type='l', ylab='Q(p)', main="Normal quantile function")

p0 <- 0.8
plot(x, dnorm(x), type='l', xlab='', ylab='f(x)')
abline(v=p0)
text(p0, 0.35, glue::glue("x = Q(p)"), pos=4)
abline(h=0)
text(p0, 0.11, glue::glue("area \nto the\nleft \n is   \n p   "), pos=2)
par()
```
- `qnorm(p, mean, sd)` returns the normal quantiles
- useful for looking up the values for hypothesis testing and confidence intervals (e.g., $z$- or $t$-values)
- For a discrete r.v., the quantile function can jump

---

## Generating random variables

- `rnorm(n, mean, sd)` generates $n$ normal r.v.s 

```{r, fig.height=4, fig.width=4, fig.align='center'}
X <- rnorm(500, 10, 2) # X ~ N(10, 2^2)
hist(X, freq=FALSE)
xx <- seq(0, 20, length.out=100)
lines(xx, dnorm(xx, 10, 2))
```

- The histogram of the random sample will approximate the underlying density, given a large sample

---

## A table of distributions R knows

| **Distribution** | **R function** | **Arguments** |
|---------|----------|---------|
|Beta | `*beta` | `shape1, shape2`|
|Binomial| `*binom`| `size, prob`|
|Cauchy| `*cauchy` | `location, scale`|
|Chi-square| `*chisq` | `df`|
|Exponential| `*exp` | `rate`|
|F| `*F` | `df1, df2`|
|Gamma| `*gamma`| `shape, rate/scale`|
|Geometric | `*geom` | `prob`|
|Poisson| `*pois` | `lambda`|
|Student's $t$ | `*t` | `df`|
|Uniform | `*unif` | `min, max`|

E.g., `dt/pt/qt/rt` stand for the density/cdf/quantile/random sample for a $t$-distribution

---

class: inverse

## Your turn


<img src="images/green.png" width=20> Generate a random sample of size $n=500$ from the Beta(1,1)

<img src="images/blue.png" width=20> Show the histogram of the random sample (use `freq=FALSE` to show the relative frequency). Overlay the density function (pdf) of a Beta(1, 1) random variable

<img src="images/green.png" width=20> Generate a random sample of 100 biased coin flips, where the head probability is 0.6. Find the proportion of heads in your sample
G

---

## Empirical cdf of your sample

The *empirical* cumulative distribution function is the cdf for the *empirical distribution* of a sample. The empirical distribution puts the same mass on each raw observation. So the empirical cdf for $\{X_1, \dots, X_n\}$ is
$$\hat{F}_{n}(x)={\frac {1}{n}}\sum _{i=1}^{n}\mathbf{1} \{X_{i}\leq x\},$$
where $\mathbf{1}\{A\}$ is the indicator function that equals 1 if $A$ is true or 0 otherwise.

---
- `ecdf(x)` takes a vector input `x` and outputs the empirical cumulative distribution function of `x`. Note that the returned value is a function

- You can evaluate or plot the returned function

```{r, fig.width=5, fig.height=5, fig.align='center'}
Fn <- ecdf(cars$speed)
Fn(c(5, 10, 15))
plot(Fn)
```

---

## Pseudo random number generation

```{r}
runif(3)
runif(3)
```

- The random numbers you generated will be most likely different, since they are random afterall

- But in fact, for efficiency, programs uses *pseudo-random* numbers.
These are generated from deterministic algorithms but behave like random numbers

- Truely random numbers are very hard to produce -- e.g., they come from astronomical noise or radioactive decay -- so are impractical for programs

---

- The pseudo-random numbers are generated from a *random seed*

- Once the random seed is set, the entire the sequence of numbers subsequently generated will be determined

- Use `set.seed(seedNumber)` to set the seed

```{r}
set.seed(1)
runif(3)
set.seed(1)
runif(3)
```

- .style[If your data analysis involves randomness, make sure to set seed before performing the analysis.] This will make your analysis reproducible and help isolating issues

- .style[Don't set seed within a function. The users of the function would set seed before calling the function]

---

## Case study: Simulating customer arrival

We are going to simulate the arrival of customers at a McDonald at lunch time.

Customers arrive at a McDonald following a Poisson process with rate 0.5 customers per minute.
That is to say, the waiting time between the arrivals of customers follows an exponential distribution with rate $\lambda=0.5$. 

On a particular day, the waiting time of the first 10 customers is
```{r, collapse=TRUE}
n <- 10
(wait <- rexp(n, rate=0.5))
```

The arrival time of the $i$th customer is
```{r, collapse=TRUE}
(arrival <- cumsum(wait))
```

---

The number of customers in the restuarant (assuming none left) at any given time $t$ in the first 5 minutes is 
```{r, collapse=TRUE, fig.width=5, fig.height=5, fig.align='center'}
Fn <- ecdf(arrival)
tVec <- seq(0, 20, length.out=1000)
plot(tVec, Fn(tVec) * n, xlab='t', ylab="Number of Customers", type="l")
```

---

How likely are we going to find the restaurant get busy and have at least 3 customers within 5 minutes after it opens?

```{r}
set.seed(1)
nDays <- 100
n <- 3
busy <- purrr::map_lgl(seq_len(nDays), function(i) {
  wait <- rexp(n, rate=0.5)
  wait3 <- sum(wait)
  wait3 <= 5
})

mean(busy)
```
---

## Sampling from a vector

- `sample(x, size, replace, prob)` takes a sample of the specified `size` from the elements of `x` 

```{r}
sample(1:5, 1)
```

- The default `replace=FALSE` *samples without replacement*. You will not get the same observation twice
```{r}
sample(1:5, 5) # same as sample(5)
```

---

- `replace=TRUE` samples *with replacement*. So every draw from the vector `x` will be put back and thus is independent. You may get the same observation twice
```{r}
sample(1:5, 10, replace=TRUE) # same as sample(5)
```

- `prob` specifies the probability weights for obtaining the elements of the vector being sampled (e.g., for simulating a biased coin). The default is equal weight
```{r}
sample(c("H", "T"), 10, replace=TRUE, prob=c(0.8, 0.2))
```

---

class: inverse

## Your turn

<img src="images/green.png" width=20> Sample 3 random rows from `iris` without replacement

<img src="images/green.png" width=20> Randomly shuffle the 3 rows

<img src="images/green.png" width=20> Sample 100 random rows from `iris` with replacement

