---
title: "Function Factories"
subtitle: "STAT486/586"
author: "Xiongtao Dai"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: [myslides.css, myslides-fonts.css]
    lib_dir: libs
    nature:
      beforeInit: "macros.js"
      highlightLines: true
      countIncrementalSlides: false
---

```{r xaringan-tile-view, echo=FALSE}
xaringanExtra::use_tile_view()
```

## Outline

- Creating a function factory

- Using function factories

- Examples


---

## Function factories

A *function factory* is a function which returns functions. In addition to `plus()` we saw before, there is a second example

```{r}
power1 <- function(exp) {
  function(x) {
    x ^ exp
  }
}
square <- power1(2)
class(square)
square(2)
```

- A function returned by a function factory is called a *manufactured function*. E.g., `square()` is a *manufactured function*. It encloses a piece of data (`exp = 2`)

---

## Built-in function factories

R has some built-in function factories, e.g., `ecdf` and `approxfun`. We are going to learn the former next week


---
## Using manufactured functions

- Some R functions take a function as input, e.g., 
    - `integrate(f, lower, upper)`, for integrating a one-dimensional function `f`. `f` must be vectorized in its input
    - `optimize(f, interval)` and `uniroot(f, interval)`, for searching for the minimum/maximum or the root (i.e., zero point) of a one-dimensional `f`
    - `optim(par, fn)`, for searching for the minimum or maximum of a multi-dimensional `fn`

- *Closures* (functions with enclosed data) are very useful in this context as input.
E.g.,
    ```{r}
    integrate(power1(3), 0, 1) # âˆ« x^3 dx from 0 to 1
    ```

- In particular, the problem of finding maximum likelihood estimate can utilize a function factory, which takes a dataset as argument and output the likelihood function (homework)

---

class: inverse

## Your turn

<img src="images/blue.png" width=20> Create a function factory that takes input `X` for a vector of data points $\{X_1,\dots,X_n\}$ and output a function 
$g(x) = n^{-1}\sum_{i=1}^n (x - X_i)^2$

<img src="images/green.png" width=20> Manufacture a function using input `c(-1, 0, 1)`. Call the manufactured function using `x=0` and make sure the result is 2/3

<img src="images/blue.png" width=20> Manufacture a function using input `cars$speed`. Use `optimize` to find the minimum point $\text{argmin}_x\, g(x)$

---

## Caution: Forced evaluation

There is a subtle bug in `power1` due to lazy evaluation
```
power1 <- function(exp) {
  function(x) {
    x ^ exp
  }
}
```
```{r}
a <- 1
linear <- power1(a)
a <- 2
linear(3)
```

- You may hope the output to be 3, because the `linear` function is made with an exponent 1 by value, at the time of its definition

- This is not the case because of lazy evaluation. The value of `a` is unevaluated when `linear` is defined, and `a` is bound to `linear` only at the first time `linear` is evaluated. At that moment, `a` equals 2

---

- To fix the issue, use `force()` to *force evaluate* `exp` before the function factory returns. The corrected function is

```{r}
power2 <- function(exp) {
  force(exp)
  function(x) {
    x ^ exp
  }
}

a <- 1
linear <- power2(a)
a <- 2
linear(3)
```

---

## One more example

The following is an example for finding the maximum likelihood estimate (MLE) of $\lambda$ using a function factory and `optimise`. 

Suppose that $X_1,\dots, X_n \sim \exp(\lambda)$. The density function is 
$$
f(x) = \lambda e^{-\lambda x}, \quad x > 0.
$$


Given data $\{X_1,\dots,X_n\}$, the log-likelihood function is 

$$ 
l(\lambda) = \sum_{i=1}^n \log f(X_i) = -\lambda \sum_i X_i + n\log(\lambda).
$$

We will write a function factory to obtain the log-likelihood given $\{X_1,\dots,X_n\}$:

```{r}
getl <- function(X) {
  force(X)
  n <- length(X)
  function(lam) {
    -lam * sum(X) + n * log(lam)
  }
}
```
---

Suppose the dataset is given by `cars$speed`. Manufacture the likelihood for this dataset:

```{r}
lCars <- getl(cars$speed)
```

Test it out:
```{r}
lCars(0.5)
```

Maximize the likelihood using `optimize`:
```{r}
res <- optimize(lCars, c(0, 100), maximum=TRUE)
```

Check that the MLE is the same as the analytical solution $\hat\lambda_{\text{MLE}} = n / \sum_{i=1}^n X_i$:
```{r}
testthat::expect_equal(res$maximum, 
                       1 / mean(cars$speed), 
                       tolerance=1e-3)
```

---

## References

- Chapters 6, 7, and 10, [Advanced R](https://adv-r.hadley.nz/index.html) by Hadley Wickham
